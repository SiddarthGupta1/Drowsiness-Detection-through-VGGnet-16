{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1832e931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "#real time capture\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"eye_state_vgg_small_eye_dataset.h5\")\n",
    "\n",
    "# Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Dlib shape predictor\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Eye landmark indices (68-point model)\n",
    "LEFT_EYE_POINTS = list(range(36, 42))\n",
    "RIGHT_EYE_POINTS = list(range(42, 48))\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "closed_start_time = None\n",
    "drowsy_alert = False\n",
    "threshold_time = 2  # seconds\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        cv2.putText(frame, \"Unknown Face\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
    "        closed_start_time = None\n",
    "        drowsy_alert = False\n",
    "    else:\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Convert to dlib rectangle\n",
    "            dlib_rect = dlib.rectangle(0, 0, w, h)\n",
    "            landmarks = predictor(roi_gray, dlib_rect)\n",
    "\n",
    "            def extract_eye(points):\n",
    "                coords = np.array([(landmarks.part(p).x, landmarks.part(p).y) for p in points])\n",
    "                ex, ey, ew, eh = cv2.boundingRect(coords)\n",
    "                eye = roi_color[ey:ey+eh, ex:ex+ew]\n",
    "                if eye.size == 0:\n",
    "                    return None, (ex,ey,ew,eh)\n",
    "                eye_resized = cv2.resize(eye, (224,224))\n",
    "                eye_normalized = eye_resized / 255.0\n",
    "                return np.expand_dims(eye_normalized, axis=0), (ex,ey,ew,eh)\n",
    "\n",
    "            left_eye, boxL = extract_eye(LEFT_EYE_POINTS)\n",
    "            right_eye, boxR = extract_eye(RIGHT_EYE_POINTS)\n",
    "\n",
    "            eye_states = []\n",
    "\n",
    "            for eye_input, box in [(left_eye, boxL), (right_eye, boxR)]:\n",
    "                if eye_input is not None:\n",
    "                    pred = model.predict(eye_input, verbose=0)[0][0]\n",
    "                    state = \"Closed\" if pred < 0.5 else \"Open\"  # adjust based on class_indices\n",
    "                    eye_states.append(state)\n",
    "\n",
    "                    (ex,ey,ew,eh) = box\n",
    "                    color = (0,255,0) if state==\"Open\" else (0,0,255)\n",
    "                    cv2.rectangle(roi_color, (ex,ey), (ex+ew,ey+eh), color, 2)\n",
    "                    cv2.putText(frame, state, (ex,ey-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "            # Check drowsiness\n",
    "            if len(eye_states) > 0 and all(s==\"Closed\" for s in eye_states):\n",
    "                if closed_start_time is None:\n",
    "                    closed_start_time = time.time()\n",
    "                else:\n",
    "                    elapsed = time.time() - closed_start_time\n",
    "                    if elapsed > threshold_time:\n",
    "                        drowsy_alert = True\n",
    "            else:\n",
    "                closed_start_time = None\n",
    "                drowsy_alert = False\n",
    "\n",
    "            if drowsy_alert:\n",
    "                cv2.putText(frame, \"DROWSINESS ALERT!\", (100,100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,0,255), 3)\n",
    "\n",
    "    cv2.imshow(\"Drowsiness Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac284f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected: ['Closed', 'Closed']\n"
     ]
    }
   ],
   "source": [
    "#image capture\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load trained model\n",
    "model = tf.keras.models.load_model(\"eye_state_vgg_small_eye_dataset.h5\")\n",
    "\n",
    "# Dlib face detector + shape predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  \n",
    "\n",
    "\n",
    "# Landmark indices for eyes (68-point model)\n",
    "LEFT_EYE_POINTS = list(range(36, 42))   # left eye\n",
    "RIGHT_EYE_POINTS = list(range(42, 48))  # right eye\n",
    "\n",
    "# Path to test image\n",
    "image_path = \"A0787.png\"\n",
    "\n",
    "# Read image\n",
    "frame = cv2.imread(image_path)\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = detector(gray)\n",
    "\n",
    "if len(faces) == 0:\n",
    "    print(\"Unknown Face\")\n",
    "else:\n",
    "    for face in faces:\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        def extract_eye(points):\n",
    "            coords = np.array([(landmarks.part(p).x, landmarks.part(p).y) for p in points])\n",
    "            x, y, w, h = cv2.boundingRect(coords)\n",
    "            eye = frame[y:y+h, x:x+w]\n",
    "            if eye.size == 0:\n",
    "                return None\n",
    "            eye_resized = cv2.resize(eye, (224,224))\n",
    "            eye_normalized = eye_resized / 255.0\n",
    "            return np.expand_dims(eye_normalized, axis=0), (x,y,w,h)\n",
    "\n",
    "        # Left eye\n",
    "        left_eye, boxL = extract_eye(LEFT_EYE_POINTS)\n",
    "        # Right eye\n",
    "        right_eye, boxR = extract_eye(RIGHT_EYE_POINTS)\n",
    "\n",
    "        eye_states = []\n",
    "\n",
    "        for eye_input, box in [(left_eye, boxL), (right_eye, boxR)]:\n",
    "            if eye_input is not None:\n",
    "                pred = model.predict(eye_input, verbose=0)[0][0]\n",
    "\n",
    "                #  adjust based on class_indices\n",
    "                state = \"Closed\" if pred < 0.5 else \"Open\"\n",
    "                eye_states.append(state)\n",
    "\n",
    "                (x,y,w,h) = box\n",
    "                color = (0,255,0) if state==\"Open\" else (0,0,255)\n",
    "                cv2.rectangle(frame, (x,y), (x+w,y+h), color, 2)\n",
    "                cv2.putText(frame, state, (x,y-10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "        if len(eye_states) > 0:\n",
    "            print(\"Detected:\", eye_states)\n",
    "\n",
    "# Show result\n",
    "cv2.imshow(\"Result\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf737b72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix, accuracy_score\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ðŸ”¹ 1. Load trained model\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "#EYE METRICS \n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ------------------------------\n",
    "# ðŸ”¹ 1. Load trained model\n",
    "# ------------------------------\n",
    "model = tf.keras.models.load_model(\"eye_state_vgg_small_eye_dataset.h5\")\n",
    "\n",
    "# ------------------------------\n",
    "# ðŸ”¹ 2. Evaluate on test dataset\n",
    "# ------------------------------\n",
    "test_dir = r\"C:\\Users\\gupta\\OneDrive\\Desktop\\computer vision project\\myeyes_2\"  # path to your test dataset\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Show detected classes and folders\n",
    "print(\"Detected classes:\", test_generator.class_indices)\n",
    "print(\"Folders in test dir:\", os.listdir(test_dir))\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(test_generator, verbose=1)\n",
    "y_pred = (y_pred > 0.5).astype(int).flatten()\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Define labels (Closed/Open)\n",
    "labels = [0, 1]\n",
    "class_names = [\"closed\", \"open\"]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nâœ… Test Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true, y_pred, labels=labels))\n",
    "print(\"\\nClassification Report:\\n\",classification_report(y_true, y_pred, labels=labels, target_names=class_names))\n",
    "\n",
    "\n",
    "\n",
    "# Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Dlib shape predictor\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# Eye landmark indices\n",
    "LEFT_EYE_POINTS = list(range(36, 42))\n",
    "RIGHT_EYE_POINTS = list(range(42, 48))\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "closed_start_time = None\n",
    "drowsy_alert = False\n",
    "threshold_time = 2        # seconds\n",
    "closed_threshold = 0.45   # lowered threshold for Closed detection\n",
    "\n",
    "print(\"\\n Starting Real-time Drowsiness Detection... Press ESC to exit.\\n\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        cv2.putText(frame, \"Unknown Face\", (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        closed_start_time = None\n",
    "        drowsy_alert = False\n",
    "    else:\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_color = frame[y:y + h, x:x + w]\n",
    "\n",
    "            dlib_rect = dlib.rectangle(0, 0, w, h)\n",
    "            landmarks = predictor(roi_gray, dlib_rect)\n",
    "\n",
    "            def extract_eye(points):\n",
    "                coords = np.array([(landmarks.part(p).x, landmarks.part(p).y) for p in points])\n",
    "                ex, ey, ew, eh = cv2.boundingRect(coords)\n",
    "                eye = roi_color[ey:ey + eh, ex:ex + ew]\n",
    "                if eye.size == 0:\n",
    "                    return None, (ex, ey, ew, eh)\n",
    "                eye_resized = cv2.resize(eye, (224, 224))\n",
    "                eye_normalized = eye_resized / 255.0\n",
    "                return np.expand_dims(eye_normalized, axis=0), (ex, ey, ew, eh)\n",
    "\n",
    "            left_eye, boxL = extract_eye(LEFT_EYE_POINTS)\n",
    "            right_eye, boxR = extract_eye(RIGHT_EYE_POINTS)\n",
    "\n",
    "            eye_states = []\n",
    "\n",
    "            for eye_input, box in [(left_eye, boxL), (right_eye, boxR)]:\n",
    "                if eye_input is not None:\n",
    "                    pred = model.predict(eye_input, verbose=0)[0][0]\n",
    "                    state = \"Closed\" if pred < closed_threshold else \"Open\"\n",
    "                    eye_states.append(state)\n",
    "\n",
    "                    (ex, ey, ew, eh) = box\n",
    "                    color = (0, 255, 0) if state == \"Open\" else (0, 0, 255)\n",
    "                    cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), color, 2)\n",
    "                    cv2.putText(frame, state, (ex, ey - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "                    # DEBUG: print prediction value\n",
    "                    print(f\"Eye prediction: {pred:.3f} -> {state}\")\n",
    "\n",
    "            # Drowsiness check\n",
    "            if len(eye_states) > 0 and all(s == \"Closed\" for s in eye_states):\n",
    "                if closed_start_time is None:\n",
    "                    closed_start_time = time.time()\n",
    "                else:\n",
    "                    elapsed = time.time() - closed_start_time\n",
    "                    if elapsed > threshold_time:\n",
    "                        drowsy_alert = True\n",
    "            else:\n",
    "                closed_start_time = None\n",
    "                drowsy_alert = False\n",
    "\n",
    "            if drowsy_alert:\n",
    "                cv2.putText(frame, \"DROWSINESS ALERT!\", (100, 100),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)\n",
    "\n",
    "    cv2.imshow(\"Drowsiness Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b9c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 315 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\OneDrive\\Desktop\\computer vision project\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ EYE MODEL CLASSES: {'closed': 0, 'open': 1}\n",
      "ðŸ”¹ Eye Test Folders: ['closed', 'open']\n",
      "\u001b[1m10/10\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step\n",
      "\n",
      "Eye Model Accuracy: 0.9015873015873016\n",
      "\n",
      "Confusion Matrix (Eyes):\n",
      " [[116  18]\n",
      " [ 13 168]]\n",
      "\n",
      "Classification Report (Eyes):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Closed_Eyes       0.90      0.87      0.88       134\n",
      "   Open_Eyes       0.90      0.93      0.92       181\n",
      "\n",
      "    accuracy                           0.90       315\n",
      "   macro avg       0.90      0.90      0.90       315\n",
      "weighted avg       0.90      0.90      0.90       315\n",
      "\n",
      "Found 630 images belonging to 2 classes.\n",
      "\n",
      " YAWN MODEL CLASSES: {'no_yawn': 0, 'yawn': 1}\n",
      " Yawn Test Folders: ['no_yawn', 'yawn']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gupta\\OneDrive\\Desktop\\computer vision project\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 3s/step\n",
      "\n",
      "Yawn Model Accuracy: 0.8984126984126984\n",
      "\n",
      "Confusion Matrix (Yawn):\n",
      " [[270   3]\n",
      " [ 61 296]]\n",
      "\n",
      "Classification Report (Yawn):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     No_yawn       0.82      0.99      0.89       273\n",
      "        Yawn       0.99      0.83      0.90       357\n",
      "\n",
      "    accuracy                           0.90       630\n",
      "   macro avg       0.90      0.91      0.90       630\n",
      "weighted avg       0.91      0.90      0.90       630\n",
      "\n",
      "\n",
      "Starting Real-time Drowsiness + Yawn Detection... Press ESC to exit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#eye plus yawn metrics\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "eye_model = tf.keras.models.load_model(\"eye_state_vgg_small_eye_dataset.h5\")\n",
    "yawn_model = tf.keras.models.load_model(\"yawn_state_model.h5\")  \n",
    "\n",
    "#evaluate eye \n",
    "eye_test_dir = r\"C:\\Users\\gupta\\OneDrive\\Desktop\\computer vision project\\myeyes_2\"\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "eye_test_gen = test_datagen.flow_from_directory(\n",
    "    eye_test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ”¹ EYE MODEL CLASSES:\", eye_test_gen.class_indices)\n",
    "print(\"ðŸ”¹ Eye Test Folders:\", os.listdir(eye_test_dir))\n",
    "\n",
    "eye_pred = eye_model.predict(eye_test_gen, verbose=1)\n",
    "eye_pred = (eye_pred > 0.5).astype(int).flatten()\n",
    "eye_true = eye_test_gen.classes\n",
    "\n",
    "eye_labels = [0, 1]\n",
    "eye_class_names = [\"Closed_Eyes\", \"Open_Eyes\"]\n",
    "\n",
    "print(\"\\nEye Model Accuracy:\", accuracy_score(eye_true, eye_pred))\n",
    "print(\"\\nConfusion Matrix (Eyes):\\n\", confusion_matrix(eye_true, eye_pred, labels=eye_labels))\n",
    "print(\"\\nClassification Report (Eyes):\\n\", classification_report(eye_true, eye_pred, labels=eye_labels, target_names=eye_class_names))\n",
    "\n",
    "#evaluate yawn\n",
    "yawn_test_dir = r\"C:\\Users\\gupta\\OneDrive\\Desktop\\computer vision project\\my_yawn\" \n",
    "\n",
    "yawn_test_gen = test_datagen.flow_from_directory(\n",
    "    yawn_test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"\\n YAWN MODEL CLASSES:\", yawn_test_gen.class_indices)\n",
    "print(\" Yawn Test Folders:\", os.listdir(yawn_test_dir))\n",
    "\n",
    "# Predict for yawn model\n",
    "yawn_pred = yawn_model.predict(yawn_test_gen, verbose=1)\n",
    "yawn_pred = (yawn_pred > 0.5).astype(int).flatten()\n",
    "yawn_true = yawn_test_gen.classes\n",
    "\n",
    "yawn_labels = [0, 1]\n",
    "yawn_class_names = [\"No_yawn\", \"Yawn\"]\n",
    "\n",
    "print(\"\\nYawn Model Accuracy:\", accuracy_score(yawn_true, yawn_pred))\n",
    "print(\"\\nConfusion Matrix (Yawn):\\n\", confusion_matrix(yawn_true, yawn_pred, labels=yawn_labels))\n",
    "print(\"\\nClassification Report (Yawn):\\n\", classification_report(yawn_true, yawn_pred, labels=yawn_labels, target_names=yawn_class_names))\n",
    "\n",
    "\n",
    "# Real-time Drowsiness Detection\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "LEFT_EYE_POINTS = list(range(36, 42))\n",
    "RIGHT_EYE_POINTS = list(range(42, 48))\n",
    "MOUTH_POINTS = list(range(48, 68))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "closed_start_time = None\n",
    "drowsy_alert = False\n",
    "threshold_time = 2\n",
    "closed_threshold = 0.45\n",
    "yawn_threshold = 0.35\n",
    "\n",
    "print(\"\\nStarting Real-time Drowsiness + Yawn Detection... Press ESC to exit.\\n\")\n",
    "\n",
    "def extract_eye(points, landmarks, roi_color):\n",
    "    coords = np.array([(landmarks.part(p).x, landmarks.part(p).y) for p in points])\n",
    "    ex, ey, ew, eh = cv2.boundingRect(coords)\n",
    "    eye = roi_color[ey:ey + eh, ex:ex + ew]\n",
    "    if eye.size == 0:\n",
    "        return None, (ex, ey, ew, eh)\n",
    "    eye_resized = cv2.resize(eye, (224, 224))\n",
    "    eye_normalized = eye_resized / 255.0\n",
    "    return np.expand_dims(eye_normalized, axis=0), (ex, ey, ew, eh)\n",
    "\n",
    "def extract_mouth(points, landmarks, roi_color):\n",
    "    coords = np.array([(landmarks.part(p).x, landmarks.part(p).y) for p in points])\n",
    "    mx, my, mw, mh = cv2.boundingRect(coords)\n",
    "    padding = 10\n",
    "    mx, my = max(mx - padding, 0), max(my - padding, 0)\n",
    "    mw = min(mw + 2 * padding, roi_color.shape[1] - mx)\n",
    "    mh = min(mh + 2 * padding, roi_color.shape[0] - my)\n",
    "    mouth = roi_color[my:my + mh, mx:mx + mw]\n",
    "    if mouth.size == 0:\n",
    "        return None, (mx, my, mw, mh)\n",
    "    mouth_resized = cv2.resize(mouth, (224, 224))\n",
    "    mouth_resized = cv2.cvtColor(mouth_resized, cv2.COLOR_BGR2RGB)\n",
    "    mouth_normalized = mouth_resized / 255.0\n",
    "    return np.expand_dims(mouth_normalized, axis=0), (mx, my, mw, mh)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        cv2.putText(frame, \"No Face Detected\", (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        closed_start_time = None\n",
    "        drowsy_alert = False\n",
    "    else:\n",
    "        for (x, y, w, h) in faces:\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_color = frame[y:y + h, x:x + w]\n",
    "            dlib_rect = dlib.rectangle(0, 0, w, h)\n",
    "            landmarks = predictor(roi_gray, dlib_rect)\n",
    "\n",
    "            # Eye detection \n",
    "            left_eye, boxL = extract_eye(LEFT_EYE_POINTS, landmarks, roi_color)\n",
    "            right_eye, boxR = extract_eye(RIGHT_EYE_POINTS, landmarks, roi_color)\n",
    "            eye_states = []\n",
    "\n",
    "            for eye_input, box in [(left_eye, boxL), (right_eye, boxR)]:\n",
    "                if eye_input is not None:\n",
    "                    pred = eye_model.predict(eye_input, verbose=0)[0][0]\n",
    "                    state = \"Closed\" if pred < closed_threshold else \"Open\"\n",
    "                    eye_states.append(state)\n",
    "                    (ex, ey, ew, eh) = box\n",
    "                    color = (0, 255, 0) if state == \"Open\" else (0, 0, 255)\n",
    "                    cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), color, 2)\n",
    "                    cv2.putText(frame, state, (x + ex, y + ey - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "            #  Yawn detection \n",
    "            mouth_input, mouth_box = extract_mouth(MOUTH_POINTS, landmarks, roi_color)\n",
    "            yawn_detected = False\n",
    "            if mouth_input is not None:\n",
    "                y_pred = yawn_model.predict(mouth_input, verbose=0)[0][0]\n",
    "                yawn_detected = y_pred > yawn_threshold\n",
    "                (mx, my, mw, mh) = mouth_box\n",
    "                color = (0, 0, 255) if yawn_detected else (0, 255, 0)\n",
    "                cv2.rectangle(roi_color, (mx, my), (mx + mw, my + mh), color, 2)\n",
    "                cv2.putText(frame, f\"Yawn: {y_pred:.2f}\", (x + mx, y + my - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "            # Drowsiness check\n",
    "            eyes_closed = len(eye_states) > 0 and all(s == \"Closed\" for s in eye_states)\n",
    "            if eyes_closed or yawn_detected:\n",
    "                if closed_start_time is None:\n",
    "                    closed_start_time = time.time()\n",
    "                else:\n",
    "                    elapsed = time.time() - closed_start_time\n",
    "                    if elapsed > threshold_time:\n",
    "                        drowsy_alert = True\n",
    "            else:\n",
    "                closed_start_time = None\n",
    "                drowsy_alert = False\n",
    "\n",
    "            if drowsy_alert:\n",
    "                cv2.putText(frame, \" DROWSINESS ALERT!\", (100, 100),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "\n",
    "    cv2.imshow(\"Drowsiness + Yawn Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
